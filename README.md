# Reinforcement Learning for Inventory Optimization

This project **uses AI to optimize inventory restocking decisions** for an e-commerce business. Instead of using **fixed manual rules**, we train an **intelligent AI agent** that **learns from experience** to **minimize stockouts**, **reduce storage costs**, and **maximize profits**.

---

## **ğŸ“Œ Introduction**
Managing inventory is one of the biggest challenges for businesses. If you **stock too much**, storage costs increase. If you **stock too little**, you **lose customers** because products run out.

This project **trains an AI agent to learn when to order more stock, when to hold, and when to reduce inventory**. The AI learns from **trial and error** using **Reinforcement Learning (RL)**.

---

## **ğŸ“Œ What is Reinforcement Learning?**
Imagine teaching a **robot to play a video game**. The robot **tries different moves**, and when it **wins points, it remembers what worked**. When it **loses points, it avoids those mistakes in the future**.

Similarly, in **this project**, we train an **AI agent** to manage inventory. It **tries different restocking strategies**, gets **rewarded for good decisions** (like avoiding stockouts) and **penalized for bad decisions** (like overstocking). Over time, the AI **learns the best way to manage stock efficiently**.

---

## **ğŸ“Œ How RL is Used in This Project**
This project **trains an AI agent** to make smart inventory decisions. The AI interacts with an **environment** that simulates an online store.

- **State (What the AI sees)** â†’ **Current stock, past sales, time of day, and demand trends**.
- **Actions (What the AI can do)** â†’  
  - `0`: **Order More Stock**  
  - `1`: **Hold Current Stock**  
  - `2`: **Reduce Stock (Clearance Sale)**  
- **Rewards (How the AI learns)** â†’  
  - âœ… **Positive Reward:** If inventory is balanced, meaning no stockouts or excess storage.  
  - âŒ **Negative Reward:** If stock runs out (lost sales) or too much stock is stored (high costs).

### **Goal:**  
The AI **learns to order stock at the right time**, reducing storage costs while ensuring products are always available.

---

## **ğŸ“Œ Understanding the Dataset**
We use an **Instacart Orders Dataset**, which contains **historical e-commerce sales data**.  

### **Key Columns in the Dataset**
| **Column** | **Description** |
|------------|----------------|
| `product_id` | Unique ID for each product |
| `order_dow` | Day of the week when the order was placed |
| `order_hour_of_day` | Time of the day when the order was placed |
| `order_count` | Number of units ordered |

### **Data Processing Steps**
1ï¸âƒ£ **Load & Merge Data** from CSV files  
2ï¸âƒ£ **Aggregate Orders** by product, day, and hour  
3ï¸âƒ£ **Create a structured dataset for RL training**  

---

## **ğŸ“Œ Defining the RL Environment**
We create a **custom Gym environment** where the AI agent interacts with inventory stock levels.

### **ğŸ— How the RL Environment Works**
- The agent starts with **some initial inventory**.
- It observes **demand trends** based on the dataset.
- It can **order stock, hold, or reduce inventory** at each time step.
- The environment **updates stock levels** and **rewards the agent** based on its decisions.

---

## **ğŸ“Œ How RL Improved Inventory Management**
Your **RL model successfully optimized inventory management** by **learning from past order patterns and making intelligent stock decisions**.

- **Stockouts Were Eliminated** â†’ The RL agent **learned to restock before products ran out**.
- **Restocking Became More Frequent & Balanced** â†’ The model **avoided overstocking while ensuring availability**.
- **Total Reward Increased (~900-1000 range)** â†’ Meaning **better profit, fewer lost sales, and reduced storage costs**.
- **Rule-Based Model Performed Poorly (-956.5)** â†’ Proving that RL **is far more efficient** at inventory management.

ğŸ“Š **Final Inventory Graph Shows:**  
- **Less extreme fluctuations** â†’ AI **makes smarter decisions**.  
- **Stockouts are reduced** â†’ RL **restocks before running out**.  

---

## **ğŸ“Œ Results & Key Insights**
| **Metric** | **RL Model** | **Rule-Based Model** | **Better?** |
|------------|------------|----------------|---------|
| **Total Reward** | **924.2** | **-956.5** | âœ… **RL Wins!** |
| **Stock Stability** | **More Stable** | **Fluctuates Too Much** | âœ… **RL Wins!** |
| **Holding Cost** | **Optimized** | **Too High** | âœ… **RL Wins!** |

---

## **ğŸ“Œ Final Takeaways**
This project **demonstrates how AI can be used to manage inventory** in an efficient and automated way.  
âœ” The RL agent **learned how to balance stock levels** dynamically.  
âœ” It **outperformed traditional rule-based inventory models**.  
âœ” The model **successfully prevented stockouts and reduced storage costs**.  

### **ğŸ“Œ Future Improvements**
ğŸš€ **Want to make it even better? Try this:**  
âœ… **Train for 500+ episodes** for even better learning.  
âœ… **Increase stockout penalty** to prevent running out of stock.  
âœ… **Deploy the trained RL model to automate real-world inventory management.**  

---


